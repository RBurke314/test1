#!/usr/bin/python

# Import the required modules
print "Initialising..."
import cv2,os
import numpy as np
from PIL import Image
import time
import sys
from matplotlib import pyplot as plt


img = cv2.imread('C:/PyProjects/VisionSystem/Vision9/detectedimg/sample04.wiki.jpg',0)
cv2.imshow('detected image',img)
cv2.waitKey(0)
cv2.destroyAllWindows()

yesChoice = ['yes','y']
noChoice = ['no','n']

def get_images_and_labels(path):
    # Append all the absolute image paths in a list image_paths
    # We will not read the image with the .sad extension in the training set
    # Rather, we will use them to test our accuracy of the training
    image_paths = [os.path.join(path, f) for f in os.listdir(path)]
    # images will contains face images
    images = []
    # labels will contains the label that is assigned to the image
    labels = []
    for image_path in image_paths:
        # Read the image and convert to grayscale
        image_pil = Image.open(image_path).convert('L')
        # Convert the image format into numpy array
        image = np.array(image_pil, 'uint8')
        # Get the label of the image
        nbr = int(os.path.split(image_path)[1].split(".")[0].replace("sample", ""))
        # Detect the face in the image
        ##faces = faceCascade.detectMultiScale(image)
        # If face is detected, append the face to images and the label to labels
        ###for (x, y, w, h) in faces:
            ##print '.',
            ##images.append(image[y: y + h, x: x + w])
            ##labels.append(nbr)
            #cv2.imshow("Adding faces to traning set...", image[y: y + h, x: x + w])
            #cv2.waitKey(50)
    # return the images list and labels list
    return images, labels

input = raw_input("Would you like to load Database? (y/n) ").lower()
if input in yesChoice:
    print "Loading Database."

    # Path to the Yale Dataset
    path = './templates'
    # Call the get_images_and_labels function and get the face images and the 
    # corresponding labels
    images, labels = get_images_and_labels(path)
    cv2.destroyAllWindows()

    # Perform the tranining
    print "Training..."
    
    #path = './detected_face'
elif input in noChoice:
    print "OK."
    exit 
else:
    print "Invalid input.\nExiting."
    exit

try:
    while True:
        input2 = raw_input("Would you like to search for people/detect faces? (y/n) ").lower()

        if input in yesChoice:
            # Append the images with the extension .sad into image_paths
            print "Searching database"
            image_paths = [os.path.join(path, f) for f in os.listdir(path) ] #if f.endswith('.sad')
            #img = cv2.imread('C:/PyProjects/VisionSystem/Vision9/templates/sample01.facebook.jpg',0)
            #template =img
            template = cv2.imread('C:/PyProjects/VisionSystem/Vision9/templates/sample01.facebook.jpg',0)
            template3 = Image.open('C:/PyProjects/VisionSystem/Vision9/templates/sample04.wiki.jpg')
            templatenp = np.array(template3, 'uint8')
            i = 0
            for image_path in image_paths:
                predict_image_pil = Image.open(image_path)
                predict_image = np.array(predict_image_pil, 'uint8')
                
                w, h = template.shape[::-1]
                # All the 6 methods for comparison in a list
                methods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR',
                'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']
                
                i += 1
                s = 'Sample ' + repr(i)
                print(s)
                for meth in methods:
                    
                    thres =90
                    newimg = Image.open(image_path)
                    npimg = np.array(newimg, 'uint8')
                    method = eval(meth)
                    #Apply template Matching
                    res = cv2.matchTemplate(npimg,templatenp,method)
                    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)
                    value = (res/1)*100
                    print(value)
                    
                    #If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum
                    if method in [cv2.TM_CCOEFF_NORMED]:
                        if value>thres:
                            print('Positive Match')
                            #cv2.imshow("resized", npimg)
                        #print(min_val)
                    else:
                        top_left = max_loc
                        #print(max_val)
                    bottom_right = (top_left[0] + w, top_left[1] + h)
                

                r = 300.0 / predict_image.shape[1]
                dim = (300, int(predict_image.shape[0] * r))
 
                # perform the actual resizing of the image and show it
                resized = cv2.resize(predict_image, dim, interpolation = cv2.INTER_AREA)

                cv2.imshow("resized", resized)
                cv2.waitKey(500)
                
            	#cv2.waitKey(0)
                
        elif input in noChoice:
            print "OK."
            exit 
        else:
            print "Invalid input.\nExiting."
            exit
## Exit, ctrl + c, Cleans up I/O's 
except KeyboardInterrupt:
    print "Closing..."
    time.sleep(0.5)
    cv.destroyAllWindows()
    sys.exit(0)
